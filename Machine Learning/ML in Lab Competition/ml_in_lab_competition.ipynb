{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.571201</td>\n",
       "      <td>1.063409</td>\n",
       "      <td>-0.303041</td>\n",
       "      <td>1.602098</td>\n",
       "      <td>-0.122985</td>\n",
       "      <td>1.120129</td>\n",
       "      <td>2.296855</td>\n",
       "      <td>1.922802</td>\n",
       "      <td>2.744089</td>\n",
       "      <td>-0.281714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>-0.143132</td>\n",
       "      <td>1.246863</td>\n",
       "      <td>-0.121985</td>\n",
       "      <td>0.879625</td>\n",
       "      <td>0.265433</td>\n",
       "      <td>-0.110920</td>\n",
       "      <td>0.019004</td>\n",
       "      <td>-0.014329</td>\n",
       "      <td>-0.733068</td>\n",
       "      <td>-0.761596</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.285398</td>\n",
       "      <td>-0.128818</td>\n",
       "      <td>0.526318</td>\n",
       "      <td>-0.953757</td>\n",
       "      <td>0.193953</td>\n",
       "      <td>-0.132575</td>\n",
       "      <td>-0.372182</td>\n",
       "      <td>0.222577</td>\n",
       "      <td>-0.055932</td>\n",
       "      <td>-0.414822</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.032639</td>\n",
       "      <td>-0.286153</td>\n",
       "      <td>0.922083</td>\n",
       "      <td>-0.928660</td>\n",
       "      <td>0.835517</td>\n",
       "      <td>0.320709</td>\n",
       "      <td>0.293862</td>\n",
       "      <td>-0.163273</td>\n",
       "      <td>1.176671</td>\n",
       "      <td>0.322280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>2.267892</td>\n",
       "      <td>1.364222</td>\n",
       "      <td>0.277339</td>\n",
       "      <td>0.652962</td>\n",
       "      <td>-0.364164</td>\n",
       "      <td>1.249994</td>\n",
       "      <td>-0.363552</td>\n",
       "      <td>0.593542</td>\n",
       "      <td>0.277651</td>\n",
       "      <td>0.589408</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID         A         B         C         D         E         F         G  \\\n",
       "0  1000  0.571201  1.063409 -0.303041  1.602098 -0.122985  1.120129  2.296855   \n",
       "1  1001 -0.143132  1.246863 -0.121985  0.879625  0.265433 -0.110920  0.019004   \n",
       "2  1002  1.285398 -0.128818  0.526318 -0.953757  0.193953 -0.132575 -0.372182   \n",
       "3  1003  0.032639 -0.286153  0.922083 -0.928660  0.835517  0.320709  0.293862   \n",
       "4  1004  2.267892  1.364222  0.277339  0.652962 -0.364164  1.249994 -0.363552   \n",
       "\n",
       "          H         I         J    Y  \n",
       "0  1.922802  2.744089 -0.281714  0.0  \n",
       "1 -0.014329 -0.733068 -0.761596  1.0  \n",
       "2  0.222577 -0.055932 -0.414822  1.0  \n",
       "3 -0.163273  1.176671  0.322280  1.0  \n",
       "4  0.593542  0.277651  0.589408  0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID    0\n",
       "A     0\n",
       "B     0\n",
       "C     0\n",
       "D     0\n",
       "E     0\n",
       "F     0\n",
       "G     0\n",
       "H     0\n",
       "I     0\n",
       "J     0\n",
       "Y     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID    0\n",
       "A     0\n",
       "B     0\n",
       "C     0\n",
       "D     0\n",
       "E     0\n",
       "F     0\n",
       "G     0\n",
       "H     0\n",
       "I     0\n",
       "J     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null Values\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features \n",
    "X_train = df_train.drop(columns=[\"ID\", \"Y\"])  \n",
    "# Labels\n",
    "y_train = df_train[\"Y\"]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (test set)\n",
    "X_test = df_test.drop(columns=[\"ID\"])  \n",
    "# Save IDs for submission\n",
    "test_ids = df_test[\"ID\"]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roybe\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network with <1000 parameters\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(8, activation=\"relu\", input_shape=(10,)),  # 10*8 + 8 = 88 params\n",
    "    keras.layers.Dense(4, activation=\"relu\"),  # 8*4 + 4 = 36 params\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")  # 4*1 + 1 = 5 params\n",
    "])\n",
    "\n",
    "# Total parameters: 88 + 36 + 5 = 129 (well under 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7953 - loss: 0.4580\n",
      "Epoch 2/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8811 - loss: 0.3199\n",
      "Epoch 3/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.8806 - loss: 0.3191\n",
      "Epoch 4/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8810 - loss: 0.3171\n",
      "Epoch 5/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.8789 - loss: 0.3220\n",
      "Epoch 6/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.8826 - loss: 0.3142\n",
      "Epoch 7/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.8798 - loss: 0.3207\n",
      "Epoch 8/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.3126\n",
      "Epoch 9/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3154\n",
      "Epoch 10/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3143\n",
      "Epoch 11/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.3135\n",
      "Epoch 12/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8822 - loss: 0.3140\n",
      "Epoch 13/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8829 - loss: 0.3107\n",
      "Epoch 14/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3127\n",
      "Epoch 15/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3105\n",
      "Epoch 16/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.3193\n",
      "Epoch 17/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8806 - loss: 0.3125\n",
      "Epoch 18/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.3129\n",
      "Epoch 19/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.3134\n",
      "Epoch 20/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.3151\n",
      "Epoch 21/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3086\n",
      "Epoch 22/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.3098\n",
      "Epoch 23/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.3126\n",
      "Epoch 24/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.3093\n",
      "Epoch 25/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3140\n",
      "Epoch 26/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8792 - loss: 0.3141\n",
      "Epoch 27/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8768 - loss: 0.3182\n",
      "Epoch 28/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8828 - loss: 0.3095\n",
      "Epoch 29/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8832 - loss: 0.3072\n",
      "Epoch 30/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8792 - loss: 0.3166\n",
      "Epoch 31/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3097\n",
      "Epoch 32/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8794 - loss: 0.3149\n",
      "Epoch 33/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8804 - loss: 0.3128\n",
      "Epoch 34/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.3172\n",
      "Epoch 35/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8852 - loss: 0.3071\n",
      "Epoch 36/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8813 - loss: 0.3131\n",
      "Epoch 37/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8822 - loss: 0.3126\n",
      "Epoch 38/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8841 - loss: 0.3055\n",
      "Epoch 39/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.3129\n",
      "Epoch 40/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8837 - loss: 0.3094\n",
      "Epoch 41/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8809 - loss: 0.3141\n",
      "Epoch 42/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.3091\n",
      "Epoch 43/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8820 - loss: 0.3123\n",
      "Epoch 44/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8806 - loss: 0.3137\n",
      "Epoch 45/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8789 - loss: 0.3162\n",
      "Epoch 46/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8811 - loss: 0.3119\n",
      "Epoch 47/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8851 - loss: 0.3051\n",
      "Epoch 48/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8813 - loss: 0.3119\n",
      "Epoch 49/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.3090\n",
      "Epoch 50/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.3108\n",
      "Epoch 51/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8813 - loss: 0.3102\n",
      "Epoch 52/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8780 - loss: 0.3164\n",
      "Epoch 53/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8806 - loss: 0.3145\n",
      "Epoch 54/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3056\n",
      "Epoch 55/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.3108\n",
      "Epoch 56/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8794 - loss: 0.3137\n",
      "Epoch 57/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8791 - loss: 0.3142\n",
      "Epoch 58/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8795 - loss: 0.3136\n",
      "Epoch 59/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.3071\n",
      "Epoch 60/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8812 - loss: 0.3071\n",
      "Epoch 61/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.3017\n",
      "Epoch 62/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8827 - loss: 0.3071\n",
      "Epoch 63/500\n",
      "\u001b[1m1938/1938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8816 - loss: 0.3131\n",
      "Epoch 64/500\n",
      "\u001b[1m1175/1938\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8807 - loss: 0.3116"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "# Prepare submission file\n",
    "submission = pd.DataFrame({\"ID\": df_test[\"ID\"], \"Y\": y_pred.flatten()})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
